[tool.poetry]
name         = "llm-music-theory"
version      = "0.1.0"
description  = "Framework for querying LLMs with music theory prompts using in-context learning and chain-of-thought."
authors      = ["Liam Pond <liam.pond@mail.mcgill.ca>"]
readme       = "README.md"

# Your Python package code lives under src/llm_music_theory
packages = [
  { include = "llm_music_theory", from = "src" }
]

# Include legacy sample data (RCM6, formerly LLM-RCM) if present. Primary dataset is fux-counterpoint.
include = [
  "data/RCM6/encoded/**",    # legacy sample music files
  "data/RCM6/prompts/**"     # legacy prompt templates and questions
]

[tool.poetry.dependencies]
python                = "^3.11"
requests              = "^2.31.0"
pyyaml                = "^6.0.1"
tqdm                  = "^4.66.1"
python-dotenv         = "^1.0.1"
# Keep OpenAI mandatory because tests rely on chatgpt model by default
openai                = "^1.78.1"
# Make other providers optional so users install only what they need
google-genai          = "^1.29.0"
anthropic             = { version = "^0.50.0", optional = true }
deepseek              = { version = "^1.0.0", optional = true }

[tool.poetry.extras]
anthropic = ["anthropic"]
google    = ["google-genai"]
deepseek  = ["deepseek"]
all       = ["anthropic", "google-genai", "deepseek"]

[tool.poetry.group.dev.dependencies]
pytest                = "^8.1.1"
pytest-cov           = "^4.0.0"

[tool.poetry.scripts]
# Now you can run with `poetry run run-single` or `poetry run run-batch`
run-single  = "llm_music_theory.cli.run_single:main"
run-batch   = "llm_music_theory.cli.run_batch:main"

[build-system]
requires    = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
